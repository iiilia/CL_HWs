{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from sys import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cmd\n",
    "import pexpect\n",
    "from subprocess import *\n",
    "from pymystem3 import Mystem\n",
    "import pymystem3 as pm\n",
    "import pymorphy2 as pm2\n",
    "from functools import reduce\n",
    "import re\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def homework_1(way):\n",
    "    in_file = way\n",
    "    out_file_1 = r'C:\\\\Users\\\\Ivanitskiy\\\\Documents\\\\CL\\\\out.txt'\n",
    "    out_file_2 = r'C:\\\\Users\\\\Ivanitskiy\\\\Documents\\\\CL\\\\out2.txt'\n",
    "    command_1 = r'mystem ' + in_file + ' '+ out_file_1\n",
    "    command_2 = r'mystem -cg ' + in_file + ' '+ out_file_2\n",
    "    call(pexpect.split_command_line(command_1))\n",
    "    call(pexpect.split_command_line(command_2))\n",
    "    df = pd.read_csv(out_file_1, sep = '{', lineterminator='}',header=None)\n",
    "    df_temp = pd.read_csv(out_file_2, sep = '{', lineterminator='}',header=None)\n",
    "    df.columns = ['word','spec']\n",
    "    df_temp.columns = ['word','spec']\n",
    "    df = df\n",
    "    df_temp = df_temp\n",
    "    df = pd.merge(df, df_temp, left_index=True, right_index=True)\n",
    "\n",
    "    # Part 1\n",
    "\n",
    "    ### Количество словоупотреблений\n",
    "    print()\n",
    "    count_of_usage = df.shape[0]\n",
    "    print('Общее число словоупотреблений = %d' % count_of_usage)\n",
    "\n",
    "    ### Количество словоформ\n",
    "    print()\n",
    "    def rep(x):\n",
    "        temp = str(x).replace('\\n','').replace('\\ufeff','').replace('\\r','').replace(',','').replace(';','').replace('...','').replace(r'.','')\n",
    "        temp = temp.replace('—','').replace('?','').replace('!','').replace(r'.','').replace('\\t','').replace(r'!','').replace(r'?','').replace(':','')\n",
    "        temp = temp.replace('\"','').replace('»','').replace('«','').replace('„','').replace('“','').replace(' ','').upper()\n",
    "        return temp\n",
    "\n",
    "    df['word_form'] = list(map(lambda x: rep(x),\n",
    "                               df['word_x']))\n",
    "\n",
    "    count_word_form = df['word_form'].nunique()\n",
    "    print('Общее число словоформ = %d' % count_word_form)\n",
    "\n",
    "    ### Число незнакомых слов\n",
    "    print()\n",
    "    m = pm.Mystem()\n",
    "    def is_known_mystem(x):\n",
    "        try:\n",
    "            temp = x[0]['analysis'][0]['qual'] == 'bastard'\n",
    "        except:\n",
    "            temp = False\n",
    "        return not temp\n",
    "\n",
    "    f = open(in_file,'r',encoding='utf8')\n",
    "    file_text = ''\n",
    "    for line in f:\n",
    "        file_text = file_text + str(line).replace('\\ufeff','').replace('\\n','')\n",
    "    result_of_text_analyze = m.analyze(file_text)\n",
    "\n",
    "    result_of_text_analyze_filter = []\n",
    "    for i in result_of_text_analyze:\n",
    "        if pd.Series(i['text']).isin([', ','. ','! ','? ','\\n','\\ufeff','„','“','«','»','-','!','?','... ',': «','...',\n",
    "                                      ' «','», — ','!» ',':«','...“ ',\n",
    "                                      '—','; ',': ','?» ',' ','.',':— ','.— ','?— ','!— ','...— ','— ',', — ',' — ']).values == False:\n",
    "            result_of_text_analyze_filter.append(i)\n",
    "    df['spec_by_python_lib_mystem'] = pd.Series(result_of_text_analyze_filter)\n",
    "\n",
    "    analyzer = pm2.MorphAnalyzer()\n",
    "    df['is_known_pymorphy2'] = list(map(lambda x: int(analyzer.word_is_known(x)), df['word_form']))\n",
    "    df['is_known_mystem'] = list(map(lambda x: int(is_known_mystem(x)), df['spec_by_python_lib_mystem']))\n",
    "    count_of_known_words_pymorphy = sum(df['is_known_pymorphy2'])\n",
    "    count_of_known_words_mystem = sum(df['is_known_mystem'])\n",
    "    print('Число слов знакомых словарю:\\n\\t* pymorphy\\t%d\\n\\t* mystem\\t%d' % (count_of_known_words_pymorphy, count_of_known_words_mystem))\n",
    "\n",
    "    ### Количество уникальных лемм\n",
    "    print()\n",
    "    result_lexem = ''\n",
    "    lexems = reduce(lambda x,y: y+x,list(map(lambda x: x+'|', df['spec_x'])))\n",
    "    lexems_set = set(lexems.split('|')[:-1])\n",
    "    # count of lexems with omonimia\n",
    "    count_of_lexems_1 = len(lexems_set)\n",
    "    # count of lexems without omonimia\n",
    "    count_of_lexems_2 = df['spec_x'].nunique()\n",
    "    print('Число лексем:\\n\\t* с учетом омонимии\\t%d\\n\\t(если одной словоформе соответствуют несколько лексем, то они все учитываются)\\n\\t* без учета омонимии\\t%d\\n\\t(при соответствии нескольким лексемам, смотрится совпадение всех предполагаемых лексем)'\n",
    "          % (count_of_lexems_1, count_of_lexems_2))\n",
    "\n",
    "    ### Коэффициент лексического богатства текста\n",
    "    print()\n",
    "    print('Коэффициент лексического богатства текста:\\n\\t* с учетом омонимии\\t%f05\\n\\t(если одной словоформе соответствуют несколько лексем, то они все учитываются)\\n\\t* без учета омонимии\\t%f05\\n\\t(при соответствии нескольким лексемам, смотрится совпадение всех предполагаемых лексем)'\n",
    "          % (count_of_lexems_1/float(count_of_usage), count_of_lexems_2/float(count_of_usage)))\n",
    "\n",
    "    # Part 2\n",
    "\n",
    "    ### Абсолютная и относительная частота омонимичных словоформ\n",
    "    print()\n",
    "    print()\n",
    "    def gr(x):\n",
    "        try:\n",
    "            return x['analysis'][0]['gr']\n",
    "        except:\n",
    "            return ''\n",
    "\n",
    "    df['count_of_lexems'] = list(map(lambda x: len(x.split('|')), df['spec_x']))\n",
    "    df['grammar'] = list(map(lambda x: gr(x).split('=')[0], df['spec_by_python_lib_mystem']))\n",
    "    unchangeable = ['PR','CONJ','PART','ADVPRO','ADV']\n",
    "    df['changeable'] = list(map(lambda x: int(not pd.Series(x).isin(unchangeable)[0]), df['grammar']))\n",
    "    count_omonimes = sum(df['count_of_lexems'] > 1)\n",
    "    count_changeable = sum(df['changeable'])\n",
    "    print('Частота омонимичных словоформ:\\n\\t* абсолютная\\t%f05\\n\\t* относительная\\t%f05'\n",
    "          % (count_omonimes/float(count_of_usage), count_omonimes/float(count_changeable)))\n",
    "\n",
    "    ### Абсолютная и относительная частота словоформ с лексико-морфологической омонимией\n",
    "    print()\n",
    "    gr = re.compile(r'=[A-Z]{1,7}[=,]{1}')\n",
    "    def gr_mystem(x):\n",
    "        return list(map(lambda x: x.replace('=','').replace(',','').replace(' ',''), gr.findall(x)))\n",
    "\n",
    "    df['grammar_omo'] = list(map(lambda x: gr_mystem(str(x)), df['spec_y']))\n",
    "    df['count_grammar'] = list(map(lambda x: len(set(x)),df['grammar_omo']))\n",
    "\n",
    "    count_of_morphy_lexical_omo = sum(df['count_grammar'] > 2)\n",
    "    print('Частота словоформ с лексико-морфологической омонимией:\\n\\t* абсолютная\\t%f05\\n\\t* относительная\\t%f05'\n",
    "          % (count_of_morphy_lexical_omo/float(count_of_usage), count_of_morphy_lexical_omo/float(count_changeable)))\n",
    "\n",
    "    ###  Максимальное и среднее число омонимов у словоформ текста\n",
    "    print()\n",
    "    max_count_of_lexems = max(df['count_of_lexems'])\n",
    "    mean_count_of_lexems = df[df['count_of_lexems']>1]['count_of_lexems'].mean()\n",
    "    print('\\t* максимальное число омонимов\\t%d\\n\\t* среднее число омонимов\\t%f'\n",
    "          % (max_count_of_lexems,mean_count_of_lexems))\n",
    "\n",
    "    ### Cловоформы с наибольшим числом омонимов\n",
    "    print()\n",
    "    word_form = df[['word_x', 'spec_x']][df['count_of_lexems'] == max_count_of_lexems]\n",
    "    word_form.columns = ['словоформа','омоним']\n",
    "    word_form = word_form.reset_index(drop = True)\n",
    "    print('У этих слов %d омонима:' % max_count_of_lexems)\n",
    "    pr_head = ['словоформа','омоним']\n",
    "    pr_tab = list(map(lambda x,y: [x,y], word_form['словоформа'], word_form['омоним']))\n",
    "    print(tabulate(pr_tab, headers=pr_head))\n",
    "    print()\n",
    "    word_form = df[['word_x', 'spec_x']][df['count_of_lexems'] == max_count_of_lexems-1]\n",
    "    word_form.columns = ['словоформа','омоним']\n",
    "    word_form = word_form.reset_index(drop = True)\n",
    "    print('У этих слов %d омонима:' % (max_count_of_lexems-1))\n",
    "    pr_head = ['словоформа','омоним']\n",
    "    pr_tab = list(map(lambda x,y: [x,y], word_form['словоформа'], word_form['омоним']))\n",
    "    print(tabulate(pr_tab, headers=pr_head))\n",
    "    ### Наиболее частотный омоним\n",
    "    print()\n",
    "    omonimes = df[df.count_of_lexems > 1]\n",
    "    temp = omonimes[['spec_x','word_x','spec_y']]\n",
    "    temp = pd.DataFrame(temp.groupby(['word_x','spec_x'])['spec_y'].count()).reset_index()\n",
    "    temp = temp[temp['spec_y']>2].reset_index(drop = True)\n",
    "    temp = temp.sort_values('spec_y',ascending=False).reset_index(drop = True)\n",
    "    temp.columns = ['словоформа','вероятные лексемы','количество']\n",
    "    print('Наиболее частотные омонимы:')\n",
    "    pr_head = ['словоформа','вероятные лексемы','количество']\n",
    "    pr_tab = list(map(lambda x,y,z: [x,y,z], temp['словоформа'],temp['вероятные лексемы'],temp['количество']))\n",
    "    print(tabulate(pr_tab, headers=pr_head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "texts = {'Бродский. Сборник стихов.':'1_brodskiy.txt', #+\n",
    "         'Бунин. Темные аллеи.':'2_bynin_tyomnye_allei.txt', #+\n",
    "         'Агния Барто. Стихи.':'3_agniya_barto.txt', #+\n",
    "         'УК РФ':'4_uk_rf.txt', #+\n",
    "         'Хэммингуэй. Старик и море.':'5_hemmingyey_starik_i_more.txt' #+\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = open('C:\\\\Users\\Ivanitskiy\\\\Documents\\\\CL\\\\report_without_tables.txt', 'w')\n",
    "for i in texts:\n",
    "    print(i)\n",
    "    homework_1(texts.get(i))\n",
    "    print('*******')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
